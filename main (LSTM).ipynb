{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import youtokentome as yttm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.dataset import BinaryDataset\n",
    "from src.model import Classifier\n",
    "from src.utils import *\n",
    "from src.vars import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86426</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90194</th>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a\n",
       "id                                                                \n",
       "86426  @USER She should ask a few native Americans wh...       OFF\n",
       "90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_file, sep='\\t', index_col='id')[['tweet', label_column]]\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'OFF': 4400, 'NOT': 8840})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_data[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\iguru\\documents\\venv\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# This file needed for tokenizer initialization\n",
    "tmp_file = 'tmp.tsv'\n",
    "prep = train_data[data_column]\n",
    "prep.to_csv(tmp_file, sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverage != 1.0, to ignore rare tokens\n",
    "tokenizer = yttm.BPE.train(data=tmp_file, coverage=0.99, vocab_size=1024, model=tokenizer_path, \n",
    "                           pad_id=pad_token_id, unk_id=unk_token_id, eos_id=sep_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"rm\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "# for win\n",
    "! del tmp.tsv\n",
    "# for unix\n",
    "! rm tmp.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epochs = 10\n",
    "batch_size = 32\n",
    "epsilon = 1e-4\n",
    "learning_rate = 0.001\n",
    "word_embedding_dim = 64\n",
    "hidden_dim = 32\n",
    "topk = 1\n",
    "fc1 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = yttm.BPE(model=tokenizer_path)\n",
    "\n",
    "x = train_data[data_column].apply(lambda r: tokenizer.encode(r))\n",
    "y = train_data[label_column]\n",
    "\n",
    "# Categorical to int\n",
    "uniq = set(y)\n",
    "mapping = dict([(k,v) for v,k in enumerate(uniq)])\n",
    "y = y.apply(lambda r: mapping[r])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x.values, y.values, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BinaryDataset(X_train,y_train)\n",
    "val_dataset = BinaryDataset(X_test, y_test)\n",
    "\n",
    "data_loader = {'train': create_dataloader(train_dataset, batch_size, pad_token_id),\n",
    "               'val': create_dataloader(val_dataset, batch_size, pad_token_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vocab size: 1024\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Init stats\n",
    "stats = {'train': {'acc': [], 'loss': []},\n",
    "         'val': {'acc': [], 'loss': []}}\n",
    "best_acc = 0\n",
    "\n",
    "word_vocab_size = tokenizer.vocab_size()\n",
    "print('Word vocab size:', word_vocab_size)\n",
    "\n",
    "# Init model.\n",
    "model = Classifier(word_vocab_size=word_vocab_size,\n",
    "                   word_embedding_dim=word_embedding_dim,\n",
    "                   hidden_dim=hidden_dim,\n",
    "                   target_size=2,\n",
    "                   fc1=fc1,\n",
    "                   padding_idx=pad_token_id,\n",
    "                   topk=topk)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5,\n",
    "                                 patience=0, verbose=True, threshold_mode='abs',\n",
    "                                 threshold=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, device, optimizer, loss_function,\n",
    "              data_loader, is_train_phase, desc=None, verbose=True):\n",
    "    \"\"\"Run the given data through the model.\n",
    "    :param model: model to run\n",
    "    :param optimizer: optimizer for the model\n",
    "    :param loss_function: function to calculate the loss\n",
    "    :param data_loader: loader for the data\n",
    "    :param is_train_phase: if true, model runs in train mode and propagate gradient, otherwise in eval mode\n",
    "    :param desc: description for the tqdm visualization\n",
    "    :param verbose: verbose state\n",
    "    :return: tuple of accuracies and losses\n",
    "    \"\"\"\n",
    "    # Setup gradient\n",
    "    if is_train_phase:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    iterable = tqdm(data_loader, desc=desc) if verbose else data_loader\n",
    "    for sentences, targets in iterable:\n",
    "        sentences = sentences.to(device)\n",
    "        targets = targets.to(device).flatten()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(is_train_phase):\n",
    "            y_hat = model(sentences)\n",
    "            loss = loss_function(y_hat, targets)\n",
    "            acc = calc_accuracy(y_hat, targets).cpu().detach().numpy()\n",
    "\n",
    "            # backprop only in train phase\n",
    "            if is_train_phase:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # store loss\n",
    "            losses.append(loss.item())\n",
    "            accuracies.append(acc)\n",
    "\n",
    "            # Update metrics in description\n",
    "            if verbose:\n",
    "                iterable.set_description(desc +\n",
    "                                         f' - acc: {np.mean(accuracies):.4f}; ' +\n",
    "                                         f'loss: {np.mean(losses):.4f}')\n",
    "\n",
    "    return accuracies, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Epoch 0 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0da260aa7c4aa5957a0cada426b3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #0', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5540948140ea464888be94a3d16e2be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #0', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Biggest val accuracy\n",
      "Saving model...\n",
      "Saved successfully\n",
      "------------ Epoch 1 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\iguru\\documents\\venv\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "c:\\users\\iguru\\documents\\venv\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "c:\\users\\iguru\\documents\\venv\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "c:\\users\\iguru\\documents\\venv\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "c:\\users\\iguru\\documents\\venv\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "c:\\users\\iguru\\documents\\venv\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "c:\\users\\iguru\\documents\\venv\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd8f9316d974da8b461a4448d54efb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #1', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfea88d83f94a3486f739fa44d669a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #1', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Biggest val accuracy\n",
      "Saving model...\n",
      "Saved successfully\n",
      "------------ Epoch 2 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505f2b84b2b2480fb002e8ecd03dcbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #2', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d145b4f985934cb8841eae21463aae54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #2', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Biggest val accuracy\n",
      "Saving model...\n",
      "Saved successfully\n",
      "------------ Epoch 3 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44b7155c3c6441aae0f6dd6a7e2292a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #3', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5b2354756c4e41b5e4767c8c5f6882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #3', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Biggest val accuracy\n",
      "Saving model...\n",
      "Saved successfully\n",
      "------------ Epoch 4 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2d5c68435648818d85af196e53ea25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #4', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632b1d6d802f48b6a63f26859768faa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #4', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     4: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Biggest val accuracy\n",
      "Saving model...\n",
      "Saved successfully\n",
      "------------ Epoch 5 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b386acf0d0724a128d96399e1facfbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #5', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8e7bf2c3994d31a9fdb3f5f578fdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #5', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     5: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Biggest val accuracy\n",
      "Saving model...\n",
      "Saved successfully\n",
      "------------ Epoch 6 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099b94bc0cd54b63b22b0c185988643b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #6', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3f370b6e684323a53c478b3bbd8c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #6', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     6: reducing learning rate of group 0 to 1.2500e-04.\n",
      "------------ Epoch 7 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0cea9b2ee84fbc911febca2bf93c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #7', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477a676a054e44d8a252dea3af9e5312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #7', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     7: reducing learning rate of group 0 to 6.2500e-05.\n",
      "------------ Epoch 8 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0ec71bbe404d2a9975aba639f1a0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #8', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10df6b1ddda94d2b9f3cb945e90b0a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #8', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     8: reducing learning rate of group 0 to 3.1250e-05.\n",
      "------------ Epoch 9 ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3164dafe5d764f9dabde9804b5f5a1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train: Epoch #9', max=331.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6692455c40774702b742942241fc2a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Val: Epoch #9', max=83.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch     9: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Finished...\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in range(num_of_epochs):\n",
    "    tqdm.write(f'------------ Epoch {epoch} ------------')\n",
    "    for phase in ['train', 'val']:\n",
    "        desc = f\"{phase.title()}: Epoch #{epoch}\"\n",
    "        epoch_accs, epoch_losses = run_model(model, device, optimizer,\n",
    "                                             loss_function, data_loader[phase],\n",
    "                                             phase == 'train', desc)\n",
    "\n",
    "        acc, loss = np.mean(epoch_accs), np.mean(epoch_losses)\n",
    "        stats[phase]['acc'].append(acc)\n",
    "        stats[phase]['loss'].append(loss)\n",
    "    # Update learning rate.\n",
    "    lr_scheduler.step(stats['val']['acc'][-1])\n",
    "    # Check best model\n",
    "    if stats['val']['acc'][-1] > best_acc:\n",
    "        best_acc = stats['val']['acc'][-1]\n",
    "        tqdm.write('Biggest val accuracy')\n",
    "        tqdm.write('Saving model...')\n",
    "        try:\n",
    "            torch.save(model, model_file)\n",
    "            tqdm.write('Saved successfully')\n",
    "        except FileNotFoundError:\n",
    "            tqdm.write('Error during saving!')\n",
    "    # Check loss change for early stopping\n",
    "    loss_change = abs(reduce(operator.sub, stats['train']['loss'][-2:]))\n",
    "    if epsilon and loss_change < epsilon:\n",
    "        print(f'Early stopping: loss change ({loss_change}) is less than {epsilon}')\n",
    "\n",
    "print('Finished...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = pd.read_csv(test_file, sep='\\t', index_col='id')[data_column].apply(lambda r: tokenizer.encode(r))\n",
    "testY = pd.read_csv(test_answer, index_col=0, header=None)[1].apply(lambda r: mapping[r]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "y_pred = [model(torch.LongTensor(x).unsqueeze(0)) for x in testX]\n",
    "y_pred = np.array([torch.max(x, dim=1)[1].item() for x in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7314\n",
      "Precision score: 0.8269\n",
      "Recall score: 0.7935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(testY, y_pred)))\n",
    "print(\"Precision score: {:.4f}\".format(precision_score(testY, y_pred)))\n",
    "print(\"Recall score: {:.4f}\".format(recall_score(testY, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
