{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-final-bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BorisAnimal/NLP-final-project/blob/lstm/main%20(bert%20-%20colab).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Phaf7Kmp3X",
        "colab_type": "code",
        "outputId": "e7383aa6-6b7e-4f3a-d562-730958d97702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "%tensorflow_version 1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTlcMphppGRH",
        "colab_type": "code",
        "outputId": "da072fbc-2735-44e2-be79-962bb35ff789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cOM3gLumu6E",
        "colab_type": "code",
        "outputId": "b1449f64-ab85-418e-d64c-7bf7fe2cfe8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "! pip install 'kashgari>=1.0.0,<2.0.0'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kashgari<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: bert4keras==0.6.5 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (0.6.5)\n",
            "Requirement already satisfied: keras-bert>=0.50.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (0.81.0)\n",
            "Requirement already satisfied: gensim>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (3.6.0)\n",
            "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (1.16.4)\n",
            "Requirement already satisfied: keras-gpt-2>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (0.14.0)\n",
            "Requirement already satisfied: seqeval==0.0.10 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (0.0.10)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (1.0.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (2.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari<2.0.0,>=1.0.0) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari<2.0.0,>=1.0.0) (1.4.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from bert4keras==0.6.5->kashgari<2.0.0,>=1.0.0) (2.3.1)\n",
            "Requirement already satisfied: keras-transformer>=0.30.0 in /usr/local/lib/python3.6/dist-packages (from keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (0.33.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (1.12.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from keras-gpt-2>=0.8.0->kashgari<2.0.0,>=1.0.0) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->kashgari<2.0.0,>=1.0.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->kashgari<2.0.0,>=1.0.0) (2018.9)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras==0.6.5->kashgari<2.0.0,>=1.0.0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras==0.6.5->kashgari<2.0.0,>=1.0.0) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras==0.6.5->kashgari<2.0.0,>=1.0.0) (3.13)\n",
            "Requirement already satisfied: keras-multi-head>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (0.22.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (0.7.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (0.6.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.12.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (0.14.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.30.0->keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (1.13.1)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (2.49.0)\n",
            "Requirement already satisfied: keras-self-attention==0.41.0 in /usr/local/lib/python3.6/dist-packages (from keras-multi-head>=0.22.0->keras-transformer>=0.30.0->keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (0.41.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (2020.4.5.1)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (1.16.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiOyfxH6H5ry",
        "colab_type": "code",
        "outputId": "3fc9ff98-4371-45da-cb9c-e6a570e59c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "! wget https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip\n",
        "! mkdir data \n",
        "! unzip OLIDv1.0.zip -d data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-07 16:27:28--  https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip\n",
            "Resolving sites.google.com (sites.google.com)... 172.217.14.78, 2607:f8b0:4007:803::200e\n",
            "Connecting to sites.google.com (sites.google.com)|172.217.14.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attredirects=0 [following]\n",
            "--2020-05-07 16:27:28--  https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attredirects=0\n",
            "Reusing existing connection to sites.google.com:443.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://ef80a887-a-62cb3a1a-s-sites.googlegroups.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attachauth=ANoY7cqVNZDfbMJGrHq0bCLZOvzSZjf31YX-bubsxQmWDxurr36KDG2tLkVa44l70_mtDrk5Oz2RPHDztvxeE-WrXIUmGsmlJTa_no8VMZSYHVwxeiNzfOXncvDxOvuH7drfyo_BPnPYwhUdnQW-2dLIMEBSHkiQr6bwna262Kaq7C7MtOJZiSeybJGzZmbzaSgPRDXp1iJCKSbyLTu_kZRrgqzR9IuGtIvKNOrqDGd9-h9gZH6qgr8%3D&attredirects=0 [following]\n",
            "--2020-05-07 16:27:28--  https://ef80a887-a-62cb3a1a-s-sites.googlegroups.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attachauth=ANoY7cqVNZDfbMJGrHq0bCLZOvzSZjf31YX-bubsxQmWDxurr36KDG2tLkVa44l70_mtDrk5Oz2RPHDztvxeE-WrXIUmGsmlJTa_no8VMZSYHVwxeiNzfOXncvDxOvuH7drfyo_BPnPYwhUdnQW-2dLIMEBSHkiQr6bwna262Kaq7C7MtOJZiSeybJGzZmbzaSgPRDXp1iJCKSbyLTu_kZRrgqzR9IuGtIvKNOrqDGd9-h9gZH6qgr8%3D&attredirects=0\n",
            "Resolving ef80a887-a-62cb3a1a-s-sites.googlegroups.com (ef80a887-a-62cb3a1a-s-sites.googlegroups.com)... 74.125.20.137, 2607:f8b0:400e:c07::89\n",
            "Connecting to ef80a887-a-62cb3a1a-s-sites.googlegroups.com (ef80a887-a-62cb3a1a-s-sites.googlegroups.com)|74.125.20.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 874644 (854K) [application/zip]\n",
            "Saving to: ‘OLIDv1.0.zip.1’\n",
            "\n",
            "OLIDv1.0.zip.1      100%[===================>] 854.14K  2.24MB/s    in 0.4s    \n",
            "\n",
            "2020-05-07 16:27:29 (2.24 MB/s) - ‘OLIDv1.0.zip.1’ saved [874644/874644]\n",
            "\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "Archive:  OLIDv1.0.zip\n",
            "replace data/olid-annotation.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: yA\n",
            "  inflating: data/olid-annotation.txt  \n",
            "replace data/olid-training-v1.0.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/olid-training-v1.0.tsv  \n",
            "  inflating: data/README.txt         \n",
            "  inflating: data/labels-levela.csv  \n",
            "  inflating: data/labels-levelb.csv  \n",
            "  inflating: data/labels-levelc.csv  \n",
            "  inflating: data/testset-levelc.tsv  \n",
            "  inflating: data/testset-levelb.tsv  \n",
            "  inflating: data/testset-levela.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkccy3h9q6_q",
        "colab_type": "code",
        "outputId": "1cd127aa-8f89-4559-f170-b1898df41430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "! wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-512_A-8.zip\n",
        "! mkdir models\n",
        "! unzip uncased_L-4_H-512_A-8.zip -d models"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-07 16:51:32--  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-512_A-8.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.5.208, 2607:f8b0:4007:801::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.5.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 107814641 (103M) [application/zip]\n",
            "Saving to: ‘uncased_L-4_H-512_A-8.zip.1’\n",
            "\n",
            "uncased_L-4_H-512_A 100%[===================>] 102.82M   168MB/s    in 0.6s    \n",
            "\n",
            "2020-05-07 16:51:33 (168 MB/s) - ‘uncased_L-4_H-512_A-8.zip.1’ saved [107814641/107814641]\n",
            "\n",
            "mkdir: cannot create directory ‘models’: File exists\n",
            "Archive:  uncased_L-4_H-512_A-8.zip\n",
            "replace models/bert_model.ckpt.data-00000-of-00001? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaZMjQ0cIw9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "01465791-7e17-49c9-ea3e-72e345acfeba"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import kashgari\n",
        "from kashgari.tasks.classification import BiGRU_Model\n",
        "from kashgari.embeddings import BERTEmbedding\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level='DEBUG')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:CUDA GPU available, you can set `kashgari.config.use_cudnn_cell = True` to use CuDNNCell. This will speed up the training, but will make model incompatible with CPU device.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwwApCO1oDLf",
        "colab_type": "code",
        "outputId": "7119821d-c2ce-4d7a-e0cd-5eec55fa46dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train = pd.read_csv('data/olid-training-v1.0.tsv', sep='\\t', index_col='id')[['tweet', 'subtask_a']]\n",
        "train.columns = ['text', 'label']\n",
        "train.head(2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>86426</th>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90194</th>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text label\n",
              "id                                                            \n",
              "86426  @USER She should ask a few native Americans wh...   OFF\n",
              "90194  @USER @USER Go home you’re drunk!!! @USER #MAG...   OFF"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie_5wy-7x5W3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "5a19c72e-fef7-4f31-d28b-fb10ec5f6c3f"
      },
      "source": [
        "bert_embed = BERTEmbedding('models',\n",
        "                           task=kashgari.CLASSIFICATION,\n",
        "                           sequence_length=128)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:22: UserWarning: bert4keras.bert has been renamed as bert4keras.models.\n",
            "  warnings.warn('bert4keras.bert has been renamed as bert4keras.models.')\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:23: UserWarning: please use bert4keras.models.\n",
            "  warnings.warn('please use bert4keras.models.')\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:44: UserWarning: bert4keras.tokenizer has been renamed as bert4keras.tokenizers.\n",
            "  warnings.warn('bert4keras.tokenizer has been renamed as bert4keras.tokenizers.')\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:45: UserWarning: please use bert4keras.tokenizers.\n",
            "  warnings.warn('please use bert4keras.tokenizers.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f50f296ebe0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f50f25dde80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f50f257db00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f50f253ac88>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f50f24bed30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f50f254c5f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f50f2568e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f50f245e908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f50f2468828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f50f1afcc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f50f250e198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f50f1b31630>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f50f1b63438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f50f1b3cbe0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f50f1a27cc0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f50f1a9e908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f50f1a5ba20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f50f19edc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f50f19ed6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f50f18d39e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f50f1957048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f50f1906ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f50f183e860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:seq_len: 128\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method NonMaskingLayer.call of <kashgari.layers.non_masking_layer.NonMaskingLayer object at 0x7f50f174a710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQRISJLJshCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = bert_embed.tokenizer\n",
        "x = train.apply(lambda r: tokenizer.tokenize(r['text']), axis=1)\n",
        "y = train['label']\n",
        "\n",
        "# train val split\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(x.values.tolist(),\n",
        "                                                      y.values.tolist(),\n",
        "                                                      test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G6rwFycolnQ",
        "colab_type": "code",
        "outputId": "7647ae25-5260-4f4b-f0c3-8a4dd120890a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "checkpoint_path = \"models/best.pth\"\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 mode='max', monitor='val_acc',\n",
        "                                                 save_best_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "model = BiGRU_Model(bert_embed)\n",
        "model.fit(train_x, train_y, valid_x, valid_y, callbacks=[cp_callback])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 128, 512), ( 15627264    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 128, 512)     1024        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 128, 512)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 128, 512)     65536       Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 128, 512)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 128, 512)     1024        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 512)     1050624     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 512)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 512)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 512)     1024        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 128, 512)     2099712     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 128, 512)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 128, 512)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 128, 512)     1024        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 512)     1050624     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 512)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 512)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 512)     1024        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 128, 512)     2099712     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 128, 512)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 128, 512)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 128, 512)     1024        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 512)     1050624     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 512)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 512)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 512)     1024        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 128, 512)     2099712     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 128, 512)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 128, 512)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 128, 512)     1024        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 512)     1050624     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 512)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 512)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 512)     1024        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 128, 512)     2099712     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 128, 512)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 128, 512)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 128, 512)     1024        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Output (Concatenate)    (None, 128, 2048)    0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "non_masking_layer (NonMaskingLa (None, 128, 2048)    0           Encoder-Output[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 256)          1671936     non_masking_layer[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            514         bidirectional[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 29,976,834\n",
            "Trainable params: 1,672,450\n",
            "Non-trainable params: 28,304,384\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "165/166 [============================>.] - ETA: 0s - loss: 0.5886 - acc: 0.7277Epoch 1/5\n",
            " 42/166 [======>.......................] - ETA: 27s - loss: 0.4808 - acc: 0.7708\n",
            "Epoch 00001: val_acc improved from -inf to 0.77077, saving model to models/best.pth\n",
            "166/166 [==============================] - 80s 484ms/step - loss: 0.5881 - acc: 0.7277 - val_loss: 0.4808 - val_acc: 0.7708\n",
            "Epoch 2/5\n",
            "165/166 [============================>.] - ETA: 0s - loss: 0.4379 - acc: 0.8017Epoch 1/5\n",
            " 42/166 [======>.......................] - ETA: 25s - loss: 0.4775 - acc: 0.7851\n",
            "Epoch 00002: val_acc improved from 0.77077 to 0.78512, saving model to models/best.pth\n",
            "166/166 [==============================] - 76s 456ms/step - loss: 0.4376 - acc: 0.8016 - val_loss: 0.4775 - val_acc: 0.7851\n",
            "Epoch 3/5\n",
            "165/166 [============================>.] - ETA: 0s - loss: 0.3888 - acc: 0.8280Epoch 1/5\n",
            " 42/166 [======>.......................] - ETA: 25s - loss: 0.4921 - acc: 0.7874\n",
            "Epoch 00003: val_acc improved from 0.78512 to 0.78739, saving model to models/best.pth\n",
            "166/166 [==============================] - 75s 449ms/step - loss: 0.3902 - acc: 0.8279 - val_loss: 0.4921 - val_acc: 0.7874\n",
            "Epoch 4/5\n",
            "165/166 [============================>.] - ETA: 0s - loss: 0.3340 - acc: 0.8603Epoch 1/5\n",
            " 42/166 [======>.......................] - ETA: 25s - loss: 0.4848 - acc: 0.7776\n",
            "Epoch 00004: val_acc did not improve from 0.78739\n",
            "166/166 [==============================] - 74s 446ms/step - loss: 0.3335 - acc: 0.8606 - val_loss: 0.4848 - val_acc: 0.7776\n",
            "Epoch 5/5\n",
            "165/166 [============================>.] - ETA: 0s - loss: 0.2674 - acc: 0.8920Epoch 1/5\n",
            " 42/166 [======>.......................] - ETA: 25s - loss: 0.5139 - acc: 0.7821\n",
            "Epoch 00005: val_acc did not improve from 0.78739\n",
            "166/166 [==============================] - 74s 448ms/step - loss: 0.2679 - acc: 0.8919 - val_loss: 0.5139 - val_acc: 0.7821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f50d9f48ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5EdyNH9GmQR",
        "colab_type": "text"
      },
      "source": [
        "### Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyABWQBuGoLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testX = pd.read_csv(\"data/testset-levela.tsv\", sep='\\t', index_col='id')['tweet'].apply(lambda r: tokenizer.tokenize(r)).values\n",
        "testY = pd.read_csv(\"data/labels-levela.csv\", index_col=0, header=None)[1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8t9hy2hGpVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(testX, batch_size=8)\n",
        "y_pred = np.array(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af-IAhMcLmAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37a617a6-e671-4d2a-bbe6-e80ac91eaaac"
      },
      "source": [
        "acc = (sum(y_pred == testY)) / len(y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc :.4f}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMQkmPyATs_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(y_pred), type(testY)\n",
        "# y_pred.shape, testY.shape\n",
        "\n",
        "uniq = set(y)\n",
        "mapping = dict([(k,v) for v,k in enumerate(uniq)])\n",
        "transform = lambda y: np.array([mapping[i] for i in y])\n",
        "y_pred = transform(y_pred)\n",
        "testY = transform(testY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvk1zgpATnHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5bcea18f-c5b0-4068-fdb7-70013d0fe714"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "print(\"Accuracy score: {:.4f}\".format(accuracy_score(testY, y_pred)))\n",
        "print(\"Precision score: {:.4f}\".format(precision_score(testY, y_pred)))\n",
        "print(\"Recall score: {:.4f}\".format(recall_score(testY, y_pred)))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.8070\n",
            "Precision score: 0.8547\n",
            "Recall score: 0.8823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33CnNOQOTnhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}